{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bf9c636-0e84-45b8-925b-d8abffe959cd",
   "metadata": {},
   "source": [
    "### Project Proposal Summary: How good are SAEs, compared to other methods in their reference class?\n",
    "\n",
    "Is a reconstruction MSE of 0.4 an impressive number? How does it compare to the top L0 PCA directions and K-means clustering with K=dvocab clusters? Are SAEs unique in archiving a good reconstruction? Maybe also answer the question for CE loss recovered.\n",
    "\n",
    "Is the monosemanticity of SAE features unique? How do baselines (clustering, PCA, probing/steering directions) compare? Test this for max- and uniform activating dataset examples This is partially inspired by Szegedy et al. (2013) who find random MNIST directions to appear interpretable. We might also compare auto interpretability scores (if we can afford the time and API keys).\n",
    "\n",
    "Is the activation distribution & sparsity of SAE latents of the form that we expect from theory & toy models? Maybe also look at things like cosine similarity distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b25d20-8eab-4da8-9d43-dda1fa351a7e",
   "metadata": {},
   "source": [
    "#### Application tasks: \n",
    "\n",
    "Consider the properties described in the summary. Which of these do you expect to differ between different SAE methodologies, how, and why? Pick 2-3 different SAE methods youâ€™re familiar with, or consider e.g. Braun et al. 2024, Geo et al. 2024, Rajamanoharan et al. 2024.\n",
    "\n",
    "Calculate & compare the MSE of two SAEs on the pile-10k dataset. Choose SAEs from different families (e.g. Geo et al. 2024 and Rajamanoharan et al. 2024).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7582d06-d6a2-4495-8948-7f73170f859f",
   "metadata": {},
   "source": [
    "1. Method 1: Sparse Autoencoder (Fully Connected)\n",
    "    A simple, fully connected sparse autoencoder with L1 regularization for sparsity.\n",
    "    Encourages sparsity directly in the latent space.\n",
    "2. Method 2: Sparse Autoencoder with K-Means Latents\n",
    "    A hybrid SAE that applies K-Means clustering on the latent space during training.\n",
    "    Enforces cluster-like representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03947bac-f023-4b2d-b02d-e8fcf144f72c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Define Metrics\n",
    "FC-SAE has a slightly lower MSE (0.4370) than K-Means-SAE (0.4750).  FC-SAE directly minimizes reconstruction error with no additional constraints, focusing purely on sparsity and reconstruction. K-Means-SAE introduces a clustering constraint in the latent space, which may reduce reconstruction flexibility, leading to higher MSE.\n",
    "\n",
    "FC-SAE latent space is unconstrained except for L1 sparsity, resulting in a dense and non-clustered representation.\n",
    "K-Means-SAE enforces discrete clustering of latent vectors, which creates structured but less flexible representations.K-Means aligns latent features with cluster centroids, sacrificing reconstruction accuracy for interpretability.\n",
    "\n",
    "\n",
    "FC-SAE explicitly enforces sparsity via L1 loss, leading to many latent dimensions being zero or near-zero.\n",
    "K-Means-SAE may have less sparsity because its clustering objective doesn't inherently enforce sparsity. L1 regularization in FC-SAE penalizes non-zero activations, whereas K-Means focuses on clustering without sparsity constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "708c4991-c31e-4825-9e98-a2a0447ae873",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (0.26.3)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging->datasets) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fd1000e-9ada-4a36-9092-5796ac93209f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load pile-10k dataset\n",
    "pile_10k = load_dataset(\"NeelNanda/pile-10k\")\n",
    "\n",
    "# Tokenize the dataset\n",
    "# Load the GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Add a padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Use the end-of-sequence token as the padding token\n",
    "\n",
    "\n",
    "# Extract text samples from the dataset\n",
    "text_samples = [sample[\"text\"] for sample in pile_10k[\"train\"]]\n",
    "\n",
    "# Tokenize the dataset in a single batch\n",
    "tokenized_batch = tokenizer(\n",
    "    text_samples,\n",
    "    return_tensors=\"pt\",  # Return PyTorch tensors\n",
    "    padding=True,         # Pad to the length of the longest sequence in the batch\n",
    "    truncation=True,      # Truncate sequences longer than the model's max length\n",
    "    max_length=512        # Set a fixed maximum length (optional)\n",
    ")\n",
    "\n",
    "# Convert tokenized inputs to input tensors\n",
    "input_data = tokenized_batch[\"input_ids\"].float()  # Shape: [batch_size, max_length]\n",
    "\n",
    "# Normalize input data\n",
    "input_data = (input_data - input_data.mean()) / input_data.std()\n",
    "\n",
    "\n",
    "# # Convert tokenized data into input tensors\n",
    "# input_data = torch.cat([sample[\"input_ids\"].float() for sample in tokenized_data])\n",
    "# input_data = (input_data - input_data.mean()) / input_data.std()  # Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efd29a48-f015-40d3-b153-6ad8a9c99ce2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SparseAutoencoderFC(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, sparsity_weight=1e-3):\n",
    "        super(SparseAutoencoderFC, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.sparsity_weight = sparsity_weight\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "    def sparsity_loss(self, encoded):\n",
    "        sparsity = torch.mean(torch.abs(encoded))\n",
    "        return self.sparsity_weight * sparsity\n",
    "\n",
    "\n",
    "class SparseAutoencoderKMeans(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, num_clusters):\n",
    "        super(SparseAutoencoderKMeans, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.num_clusters = num_clusters\n",
    "        self.kmeans = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        # Apply K-means clustering in latent space\n",
    "        cluster_assignments = self.kmeans.fit_predict(encoded.detach().cpu().numpy())\n",
    "        cluster_centers = torch.tensor(self.kmeans.cluster_centers_, device=x.device)\n",
    "        clustered_latents = cluster_centers[cluster_assignments]\n",
    "        decoded = self.decoder(clustered_latents)\n",
    "        return encoded, decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5091bca-1480-4c2c-82bd-bf9b39957b48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.0156\n",
      "Epoch 2/100, Loss: 0.0143\n",
      "Epoch 3/100, Loss: 0.0142\n",
      "Epoch 4/100, Loss: 0.0141\n",
      "Epoch 5/100, Loss: 0.0141\n",
      "Epoch 6/100, Loss: 0.0141\n",
      "Epoch 7/100, Loss: 0.0140\n",
      "Epoch 8/100, Loss: 0.0140\n",
      "Epoch 9/100, Loss: 0.0140\n",
      "Epoch 10/100, Loss: 0.0140\n",
      "Epoch 11/100, Loss: 0.0140\n",
      "Epoch 12/100, Loss: 0.0140\n",
      "Epoch 13/100, Loss: 0.0140\n",
      "Epoch 14/100, Loss: 0.0140\n",
      "Epoch 15/100, Loss: 0.0140\n",
      "Epoch 16/100, Loss: 0.0140\n",
      "Epoch 17/100, Loss: 0.0140\n",
      "Epoch 18/100, Loss: 0.0139\n",
      "Epoch 19/100, Loss: 0.0139\n",
      "Epoch 20/100, Loss: 0.0139\n",
      "Epoch 21/100, Loss: 0.0139\n",
      "Epoch 22/100, Loss: 0.0139\n",
      "Epoch 23/100, Loss: 0.0139\n",
      "Epoch 24/100, Loss: 0.0139\n",
      "Epoch 25/100, Loss: 0.0139\n",
      "Epoch 26/100, Loss: 0.0139\n",
      "Epoch 27/100, Loss: 0.0139\n",
      "Epoch 28/100, Loss: 0.0139\n",
      "Epoch 29/100, Loss: 0.0139\n",
      "Epoch 30/100, Loss: 0.0139\n",
      "Epoch 31/100, Loss: 0.0139\n",
      "Epoch 32/100, Loss: 0.0139\n",
      "Epoch 33/100, Loss: 0.0139\n",
      "Epoch 34/100, Loss: 0.0139\n",
      "Epoch 35/100, Loss: 0.0139\n",
      "Epoch 36/100, Loss: 0.0139\n",
      "Epoch 37/100, Loss: 0.0139\n",
      "Epoch 38/100, Loss: 0.0139\n",
      "Epoch 39/100, Loss: 0.0139\n",
      "Epoch 40/100, Loss: 0.0139\n",
      "Epoch 41/100, Loss: 0.0139\n",
      "Epoch 42/100, Loss: 0.0139\n",
      "Epoch 43/100, Loss: 0.0139\n",
      "Epoch 44/100, Loss: 0.0139\n",
      "Epoch 45/100, Loss: 0.0139\n",
      "Epoch 46/100, Loss: 0.0139\n",
      "Epoch 47/100, Loss: 0.0139\n",
      "Epoch 48/100, Loss: 0.0139\n",
      "Epoch 49/100, Loss: 0.0139\n",
      "Epoch 50/100, Loss: 0.0139\n",
      "Epoch 51/100, Loss: 0.0139\n",
      "Epoch 52/100, Loss: 0.0139\n",
      "Epoch 53/100, Loss: 0.0139\n",
      "Epoch 54/100, Loss: 0.0139\n",
      "Epoch 55/100, Loss: 0.0139\n",
      "Epoch 56/100, Loss: 0.0139\n",
      "Epoch 57/100, Loss: 0.0139\n",
      "Epoch 58/100, Loss: 0.0139\n",
      "Epoch 59/100, Loss: 0.0139\n",
      "Epoch 60/100, Loss: 0.0139\n",
      "Epoch 61/100, Loss: 0.0139\n",
      "Epoch 62/100, Loss: 0.0138\n",
      "Epoch 63/100, Loss: 0.0138\n",
      "Epoch 64/100, Loss: 0.0138\n",
      "Epoch 65/100, Loss: 0.0138\n",
      "Epoch 66/100, Loss: 0.0138\n",
      "Epoch 67/100, Loss: 0.0138\n",
      "Epoch 68/100, Loss: 0.0138\n",
      "Epoch 69/100, Loss: 0.0138\n",
      "Epoch 70/100, Loss: 0.0138\n",
      "Epoch 71/100, Loss: 0.0138\n",
      "Epoch 72/100, Loss: 0.0138\n",
      "Epoch 73/100, Loss: 0.0138\n",
      "Epoch 74/100, Loss: 0.0138\n",
      "Epoch 75/100, Loss: 0.0138\n",
      "Epoch 76/100, Loss: 0.0138\n",
      "Epoch 77/100, Loss: 0.0138\n",
      "Epoch 78/100, Loss: 0.0138\n",
      "Epoch 79/100, Loss: 0.0138\n",
      "Epoch 80/100, Loss: 0.0138\n",
      "Epoch 81/100, Loss: 0.0138\n",
      "Epoch 82/100, Loss: 0.0138\n",
      "Epoch 83/100, Loss: 0.0138\n",
      "Epoch 84/100, Loss: 0.0138\n",
      "Epoch 85/100, Loss: 0.0138\n",
      "Epoch 86/100, Loss: 0.0138\n",
      "Epoch 87/100, Loss: 0.0137\n",
      "Epoch 88/100, Loss: 0.0137\n",
      "Epoch 89/100, Loss: 0.0137\n",
      "Epoch 90/100, Loss: 0.0137\n",
      "Epoch 91/100, Loss: 0.0137\n",
      "Epoch 92/100, Loss: 0.0137\n",
      "Epoch 93/100, Loss: 0.0137\n",
      "Epoch 94/100, Loss: 0.0137\n",
      "Epoch 95/100, Loss: 0.0137\n",
      "Epoch 96/100, Loss: 0.0137\n",
      "Epoch 97/100, Loss: 0.0137\n",
      "Epoch 98/100, Loss: 0.0137\n",
      "Epoch 99/100, Loss: 0.0137\n",
      "Epoch 100/100, Loss: 0.0137\n",
      "Epoch 1/100, Loss: 0.0224\n",
      "Epoch 2/100, Loss: 0.0165\n",
      "Epoch 3/100, Loss: 0.0157\n",
      "Epoch 4/100, Loss: 0.0153\n",
      "Epoch 5/100, Loss: 0.0151\n",
      "Epoch 6/100, Loss: 0.0150\n",
      "Epoch 7/100, Loss: 0.0149\n",
      "Epoch 8/100, Loss: 0.0149\n",
      "Epoch 9/100, Loss: 0.0148\n",
      "Epoch 10/100, Loss: 0.0148\n",
      "Epoch 11/100, Loss: 0.0147\n",
      "Epoch 12/100, Loss: 0.0147\n",
      "Epoch 13/100, Loss: 0.0147\n",
      "Epoch 14/100, Loss: 0.0147\n",
      "Epoch 15/100, Loss: 0.0147\n",
      "Epoch 16/100, Loss: 0.0147\n",
      "Epoch 17/100, Loss: 0.0147\n",
      "Epoch 18/100, Loss: 0.0146\n",
      "Epoch 19/100, Loss: 0.0146\n",
      "Epoch 20/100, Loss: 0.0146\n",
      "Epoch 21/100, Loss: 0.0146\n",
      "Epoch 22/100, Loss: 0.0146\n",
      "Epoch 23/100, Loss: 0.0146\n",
      "Epoch 24/100, Loss: 0.0146\n",
      "Epoch 25/100, Loss: 0.0146\n",
      "Epoch 26/100, Loss: 0.0146\n",
      "Epoch 27/100, Loss: 0.0146\n",
      "Epoch 28/100, Loss: 0.0146\n",
      "Epoch 29/100, Loss: 0.0146\n",
      "Epoch 30/100, Loss: 0.0146\n",
      "Epoch 31/100, Loss: 0.0146\n",
      "Epoch 32/100, Loss: 0.0146\n",
      "Epoch 33/100, Loss: 0.0146\n",
      "Epoch 34/100, Loss: 0.0146\n",
      "Epoch 35/100, Loss: 0.0146\n",
      "Epoch 36/100, Loss: 0.0146\n",
      "Epoch 37/100, Loss: 0.0146\n",
      "Epoch 38/100, Loss: 0.0146\n",
      "Epoch 39/100, Loss: 0.0146\n",
      "Epoch 40/100, Loss: 0.0146\n",
      "Epoch 41/100, Loss: 0.0146\n",
      "Epoch 42/100, Loss: 0.0146\n",
      "Epoch 43/100, Loss: 0.0145\n",
      "Epoch 44/100, Loss: 0.0146\n",
      "Epoch 45/100, Loss: 0.0146\n",
      "Epoch 46/100, Loss: 0.0146\n",
      "Epoch 47/100, Loss: 0.0146\n",
      "Epoch 48/100, Loss: 0.0145\n",
      "Epoch 49/100, Loss: 0.0146\n",
      "Epoch 50/100, Loss: 0.0145\n",
      "Epoch 51/100, Loss: 0.0146\n",
      "Epoch 52/100, Loss: 0.0145\n",
      "Epoch 53/100, Loss: 0.0145\n",
      "Epoch 54/100, Loss: 0.0145\n",
      "Epoch 55/100, Loss: 0.0145\n",
      "Epoch 56/100, Loss: 0.0145\n",
      "Epoch 57/100, Loss: 0.0145\n",
      "Epoch 58/100, Loss: 0.0145\n",
      "Epoch 59/100, Loss: 0.0145\n",
      "Epoch 60/100, Loss: 0.0145\n",
      "Epoch 61/100, Loss: 0.0145\n",
      "Epoch 62/100, Loss: 0.0145\n",
      "Epoch 63/100, Loss: 0.0145\n",
      "Epoch 64/100, Loss: 0.0145\n",
      "Epoch 65/100, Loss: 0.0145\n",
      "Epoch 66/100, Loss: 0.0145\n",
      "Epoch 67/100, Loss: 0.0145\n",
      "Epoch 68/100, Loss: 0.0145\n",
      "Epoch 69/100, Loss: 0.0146\n",
      "Epoch 70/100, Loss: 0.0146\n",
      "Epoch 71/100, Loss: 0.0145\n",
      "Epoch 72/100, Loss: 0.0145\n",
      "Epoch 73/100, Loss: 0.0145\n",
      "Epoch 74/100, Loss: 0.0145\n",
      "Epoch 75/100, Loss: 0.0145\n",
      "Epoch 76/100, Loss: 0.0145\n",
      "Epoch 77/100, Loss: 0.0145\n",
      "Epoch 78/100, Loss: 0.0145\n",
      "Epoch 79/100, Loss: 0.0145\n",
      "Epoch 80/100, Loss: 0.0145\n",
      "Epoch 81/100, Loss: 0.0145\n",
      "Epoch 82/100, Loss: 0.0145\n",
      "Epoch 83/100, Loss: 0.0145\n",
      "Epoch 84/100, Loss: 0.0145\n",
      "Epoch 85/100, Loss: 0.0145\n",
      "Epoch 86/100, Loss: 0.0145\n",
      "Epoch 87/100, Loss: 0.0145\n",
      "Epoch 88/100, Loss: 0.0145\n",
      "Epoch 89/100, Loss: 0.0145\n",
      "Epoch 90/100, Loss: 0.0145\n",
      "Epoch 91/100, Loss: 0.0145\n",
      "Epoch 92/100, Loss: 0.0145\n",
      "Epoch 93/100, Loss: 0.0145\n",
      "Epoch 94/100, Loss: 0.0145\n",
      "Epoch 95/100, Loss: 0.0145\n",
      "Epoch 96/100, Loss: 0.0145\n",
      "Epoch 97/100, Loss: 0.0145\n",
      "Epoch 98/100, Loss: 0.0145\n",
      "Epoch 99/100, Loss: 0.0145\n",
      "Epoch 100/100, Loss: 0.0145\n"
     ]
    }
   ],
   "source": [
    "def train_sae(model, data, epochs=100, batch_size=32, lr=1e-3):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for i in range(0, len(data), batch_size):\n",
    "            batch = data[i:i+batch_size]\n",
    "            optimizer.zero_grad()\n",
    "            encoded, decoded = model(batch)\n",
    "            loss = criterion(decoded, batch) + (model.sparsity_loss(encoded) if hasattr(model, 'sparsity_loss') else 0)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(data):.4f}\")\n",
    "\n",
    "# Train both models\n",
    "fc_autoencoder = SparseAutoencoderFC(input_dim=input_data.size(1), latent_dim=128)\n",
    "train_sae(fc_autoencoder, input_data)\n",
    "\n",
    "kmeans_autoencoder = SparseAutoencoderKMeans(input_dim=input_data.size(1), latent_dim=128, num_clusters=10)\n",
    "train_sae(kmeans_autoencoder, input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2626cf7b-1208-4312-b4e6-b86b4c7c72a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (Fully Connected SAE): 0.4370\n",
      "MSE (K-Means SAE): 0.4750\n"
     ]
    }
   ],
   "source": [
    "# Evaluate reconstruction MSE\n",
    "def evaluate_mse(model, data):\n",
    "    model.eval()\n",
    "    criterion = nn.MSELoss()\n",
    "    with torch.no_grad():\n",
    "        _, decoded = model(data)\n",
    "        mse = criterion(decoded, data)\n",
    "    return mse.item()\n",
    "\n",
    "mse_fc = evaluate_mse(fc_autoencoder, input_data)\n",
    "mse_kmeans = evaluate_mse(kmeans_autoencoder, input_data)\n",
    "\n",
    "print(f\"MSE (Fully Connected SAE): {mse_fc:.4f}\")\n",
    "print(f\"MSE (K-Means SAE): {mse_kmeans:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c74f86f-7cd0-4e70-88e7-9b7afe72292b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
